{"cells":[{"cell_type":"markdown","metadata":{"id":"hcDpkPWlgLTM"},"source":["### CUDA 버전 확인하기\n","\n","- !nvidia-smi\n","- !nvcc --version\n","\n","둘의 차이점은\n","nvidia-smi는 해당 장치에서 설치 가능한 가장 높은 버전을 보여주고,\n","nvcc --version은 현재 설치된 cuda 버전을 보여줌\n","\n","출처 : https://stackoverflow.com/questions/9727688/how-to-get-the-cuda-version"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xBjhMOvSgAZH","executionInfo":{"status":"ok","timestamp":1689828900461,"user_tz":-540,"elapsed":404,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[],"source":["gpu_info = !nvcc --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kxr_SAY-zRfH","outputId":"58bdc84d-cf58-43ab-cf83-37a6decb1110","executionInfo":{"status":"ok","timestamp":1689828904809,"user_tz":-540,"elapsed":286,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["gpu_info = '\\n'.join(gpu_info)\n","print(gpu_info)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttqUGq2AgKk7","outputId":"ab7546e6-9fe7-4828-ee2c-ba43cd1a93e3","executionInfo":{"status":"ok","timestamp":1689828933570,"user_tz":-540,"elapsed":440,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jul 20 04:55:33 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epE_X6qbyoQ0","outputId":"cab15f82-57f9-4785-d977-0674946b2989","executionInfo":{"status":"ok","timestamp":1689828944432,"user_tz":-540,"elapsed":4287,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}],"source":["# PyTorch 2.x 버전 설치\n","try:\n","    # 기본적으로 https://pytorch.kr/get-started/locally/ 에서\n","    # cuda 버전과 패키지매니저에 맞는 설치 명령어를 확인 가능\n","    # %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","    import torch\n","    print(torch.__version__)\n","except:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"dwr6-f65iUA_"},"source":["----------------------------------------------------------\n","\n","# VGGNet 직접 구현하기"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Cxz1VK5-iQCJ","executionInfo":{"status":"ok","timestamp":1689828950653,"user_tz":-540,"elapsed":686,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[],"source":["# pytorch에서 사용할 함수들 호출하기\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HD6OWIBdzYIJ","outputId":"ab10d501-133e-4b8d-a1d2-866546af94a6","executionInfo":{"status":"ok","timestamp":1689829304790,"user_tz":-540,"elapsed":352943,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2640397119/2640397119 [04:58<00:00, 8854871.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/stl10_binary.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# 데이터가 상당히 크기 때문에 시간이 좀 소요됨\n","transform = transforms.Compose([\n","    transforms.Resize(72),      # image 사이즈 조정\n","    transforms.RandomCrop(56),  # image 자리\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5 ), (0.5, 0.5, 0.5 )),\n","])\n","\n","train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n","# train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n","\n","test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=transform)\n","# test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"]},{"cell_type":"markdown","source":["### 1) VGGNet11 구현"],"metadata":{"id":"Kya_VO3m_ztE"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"kSzu-cbjzir3","executionInfo":{"status":"ok","timestamp":1689833362495,"user_tz":-540,"elapsed":256,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[],"source":["class VGGNet11(nn.Module):\n","\n","    def __init__(self, num_classes=10):\n","        super(VGGNet11, self).__init__()\n","        self.convnet = nn.Sequential(\n","            # 여기에 CNN 모델을 구현해주세요.\n","            # input image size = 3x56x56\n","            nn.Conv2d(3, 64, 3, 1, 1),\n","            # 64x56x56\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 64x28x28\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","            # 128x28x28\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 128x14x14\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","            # 256x14x14\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 256x7x7\n","            nn.Conv2d(256, 512, 3, 1, 1),\n","            # 512x7x7\n","            nn.ReLU(True),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 512x3x3\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2)) # 512x1x1\n","\n","        self.fclayer = nn.Sequential(\n","            # 여기에 FC 모델을 구현해주세요.\n","            nn.Linear(512, num_classes),\n","            # nn.Softmax()\n","        )\n","\n","    def forward(self, x):\n","        x = self.convnet(x)\n","        x = torch.flatten(x, 1)\n","        output = self.fclayer(x)\n","        return output"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"JemPQZpt2rx6","executionInfo":{"status":"ok","timestamp":1689833365233,"user_tz":-540,"elapsed":417,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[],"source":["model = VGGNet11(num_classes=10)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"cA6zUQHj27kU","executionInfo":{"status":"ok","timestamp":1689833366059,"user_tz":-540,"elapsed":2,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[],"source":["# 학습을 위한 설정\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters(),lr=1e-5)\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmw2gd4c2t1D","outputId":"6a5eb474-1b1c-4036-b80d-e36828a94b60","executionInfo":{"status":"ok","timestamp":1689833939278,"user_tz":-540,"elapsed":572081,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.305196\n","Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.302308\n","\n","Test set: Average loss: 0.0092, Accuracy: 800/8000 (10%)\n","\n","Train Epoch: 2 [0/5000 (0%)]\tLoss: 2.302139\n","Train Epoch: 2 [2560/5000 (50%)]\tLoss: 2.300629\n","\n","Test set: Average loss: 0.0092, Accuracy: 800/8000 (10%)\n","\n","Train Epoch: 3 [0/5000 (0%)]\tLoss: 2.300173\n","Train Epoch: 3 [2560/5000 (50%)]\tLoss: 2.297762\n","\n","Test set: Average loss: 0.0092, Accuracy: 906/8000 (11%)\n","\n","Train Epoch: 4 [0/5000 (0%)]\tLoss: 2.288206\n","Train Epoch: 4 [2560/5000 (50%)]\tLoss: 2.268679\n","\n","Test set: Average loss: 0.0089, Accuracy: 1614/8000 (20%)\n","\n","Train Epoch: 5 [0/5000 (0%)]\tLoss: 2.236389\n","Train Epoch: 5 [2560/5000 (50%)]\tLoss: 2.157365\n","\n","Test set: Average loss: 0.0084, Accuracy: 1682/8000 (21%)\n","\n","Train Epoch: 6 [0/5000 (0%)]\tLoss: 2.088343\n","Train Epoch: 6 [2560/5000 (50%)]\tLoss: 2.041504\n","\n","Test set: Average loss: 0.0082, Accuracy: 1792/8000 (22%)\n","\n","Train Epoch: 7 [0/5000 (0%)]\tLoss: 2.080615\n","Train Epoch: 7 [2560/5000 (50%)]\tLoss: 2.076967\n","\n","Test set: Average loss: 0.0080, Accuracy: 1997/8000 (25%)\n","\n","Train Epoch: 8 [0/5000 (0%)]\tLoss: 1.981223\n","Train Epoch: 8 [2560/5000 (50%)]\tLoss: 2.012124\n","\n","Test set: Average loss: 0.0079, Accuracy: 2050/8000 (26%)\n","\n","Train Epoch: 9 [0/5000 (0%)]\tLoss: 1.973152\n","Train Epoch: 9 [2560/5000 (50%)]\tLoss: 1.983921\n","\n","Test set: Average loss: 0.0077, Accuracy: 2260/8000 (28%)\n","\n","Train Epoch: 10 [0/5000 (0%)]\tLoss: 1.916579\n","Train Epoch: 10 [2560/5000 (50%)]\tLoss: 1.865623\n","\n","Test set: Average loss: 0.0076, Accuracy: 2341/8000 (29%)\n","\n","Train Epoch: 11 [0/5000 (0%)]\tLoss: 1.835411\n","Train Epoch: 11 [2560/5000 (50%)]\tLoss: 1.904864\n","\n","Test set: Average loss: 0.0074, Accuracy: 2351/8000 (29%)\n","\n","Train Epoch: 12 [0/5000 (0%)]\tLoss: 1.848780\n","Train Epoch: 12 [2560/5000 (50%)]\tLoss: 1.881403\n","\n","Test set: Average loss: 0.0073, Accuracy: 2406/8000 (30%)\n","\n","Train Epoch: 13 [0/5000 (0%)]\tLoss: 1.849803\n","Train Epoch: 13 [2560/5000 (50%)]\tLoss: 1.762341\n","\n","Test set: Average loss: 0.0073, Accuracy: 2406/8000 (30%)\n","\n","Train Epoch: 14 [0/5000 (0%)]\tLoss: 1.811895\n","Train Epoch: 14 [2560/5000 (50%)]\tLoss: 1.784966\n","\n","Test set: Average loss: 0.0074, Accuracy: 2407/8000 (30%)\n","\n","Train Epoch: 15 [0/5000 (0%)]\tLoss: 1.973372\n","Train Epoch: 15 [2560/5000 (50%)]\tLoss: 1.723639\n","\n","Test set: Average loss: 0.0072, Accuracy: 2456/8000 (31%)\n","\n","Train Epoch: 16 [0/5000 (0%)]\tLoss: 1.776884\n","Train Epoch: 16 [2560/5000 (50%)]\tLoss: 1.775598\n","\n","Test set: Average loss: 0.0070, Accuracy: 2505/8000 (31%)\n","\n","Train Epoch: 17 [0/5000 (0%)]\tLoss: 1.760296\n","Train Epoch: 17 [2560/5000 (50%)]\tLoss: 1.668332\n","\n","Test set: Average loss: 0.0070, Accuracy: 2542/8000 (32%)\n","\n","Train Epoch: 18 [0/5000 (0%)]\tLoss: 1.734894\n","Train Epoch: 18 [2560/5000 (50%)]\tLoss: 1.742720\n","\n","Test set: Average loss: 0.0070, Accuracy: 2592/8000 (32%)\n","\n","Train Epoch: 19 [0/5000 (0%)]\tLoss: 1.686215\n","Train Epoch: 19 [2560/5000 (50%)]\tLoss: 1.712801\n","\n","Test set: Average loss: 0.0069, Accuracy: 2602/8000 (33%)\n","\n","Train Epoch: 20 [0/5000 (0%)]\tLoss: 1.694119\n","Train Epoch: 20 [2560/5000 (50%)]\tLoss: 1.683410\n","\n","Test set: Average loss: 0.0068, Accuracy: 2714/8000 (34%)\n","\n","Train Epoch: 21 [0/5000 (0%)]\tLoss: 1.716737\n","Train Epoch: 21 [2560/5000 (50%)]\tLoss: 1.721080\n","\n","Test set: Average loss: 0.0068, Accuracy: 2589/8000 (32%)\n","\n","Train Epoch: 22 [0/5000 (0%)]\tLoss: 1.747030\n","Train Epoch: 22 [2560/5000 (50%)]\tLoss: 1.724610\n","\n","Test set: Average loss: 0.0068, Accuracy: 2639/8000 (33%)\n","\n","Train Epoch: 23 [0/5000 (0%)]\tLoss: 1.669498\n","Train Epoch: 23 [2560/5000 (50%)]\tLoss: 1.686330\n","\n","Test set: Average loss: 0.0069, Accuracy: 2620/8000 (33%)\n","\n","Train Epoch: 24 [0/5000 (0%)]\tLoss: 1.759768\n","Train Epoch: 24 [2560/5000 (50%)]\tLoss: 1.708241\n","\n","Test set: Average loss: 0.0068, Accuracy: 2702/8000 (34%)\n","\n","Train Epoch: 25 [0/5000 (0%)]\tLoss: 1.670895\n","Train Epoch: 25 [2560/5000 (50%)]\tLoss: 1.802269\n","\n","Test set: Average loss: 0.0068, Accuracy: 2679/8000 (33%)\n","\n","Train Epoch: 26 [0/5000 (0%)]\tLoss: 1.561223\n","Train Epoch: 26 [2560/5000 (50%)]\tLoss: 1.666543\n","\n","Test set: Average loss: 0.0068, Accuracy: 2644/8000 (33%)\n","\n","Train Epoch: 27 [0/5000 (0%)]\tLoss: 1.606049\n","Train Epoch: 27 [2560/5000 (50%)]\tLoss: 1.684253\n","\n","Test set: Average loss: 0.0068, Accuracy: 2709/8000 (34%)\n","\n","Train Epoch: 28 [0/5000 (0%)]\tLoss: 1.748777\n","Train Epoch: 28 [2560/5000 (50%)]\tLoss: 1.618951\n","\n","Test set: Average loss: 0.0067, Accuracy: 2724/8000 (34%)\n","\n","Train Epoch: 29 [0/5000 (0%)]\tLoss: 1.728972\n","Train Epoch: 29 [2560/5000 (50%)]\tLoss: 1.718711\n","\n","Test set: Average loss: 0.0067, Accuracy: 2721/8000 (34%)\n","\n","Train Epoch: 30 [0/5000 (0%)]\tLoss: 1.742115\n","Train Epoch: 30 [2560/5000 (50%)]\tLoss: 1.670637\n","\n","Test set: Average loss: 0.0066, Accuracy: 2756/8000 (34%)\n","\n","Train Epoch: 31 [0/5000 (0%)]\tLoss: 1.556960\n","Train Epoch: 31 [2560/5000 (50%)]\tLoss: 1.644708\n","\n","Test set: Average loss: 0.0066, Accuracy: 2764/8000 (35%)\n","\n","Train Epoch: 32 [0/5000 (0%)]\tLoss: 1.703792\n","Train Epoch: 32 [2560/5000 (50%)]\tLoss: 1.649999\n","\n","Test set: Average loss: 0.0066, Accuracy: 2731/8000 (34%)\n","\n","Train Epoch: 33 [0/5000 (0%)]\tLoss: 1.620781\n","Train Epoch: 33 [2560/5000 (50%)]\tLoss: 1.620229\n","\n","Test set: Average loss: 0.0066, Accuracy: 2798/8000 (35%)\n","\n","Train Epoch: 34 [0/5000 (0%)]\tLoss: 1.623307\n","Train Epoch: 34 [2560/5000 (50%)]\tLoss: 1.638931\n","\n","Test set: Average loss: 0.0066, Accuracy: 2787/8000 (35%)\n","\n","Train Epoch: 35 [0/5000 (0%)]\tLoss: 1.674716\n","Train Epoch: 35 [2560/5000 (50%)]\tLoss: 1.666136\n","\n","Test set: Average loss: 0.0066, Accuracy: 2826/8000 (35%)\n","\n","Train Epoch: 36 [0/5000 (0%)]\tLoss: 1.695005\n","Train Epoch: 36 [2560/5000 (50%)]\tLoss: 1.614696\n","\n","Test set: Average loss: 0.0066, Accuracy: 2780/8000 (35%)\n","\n","Train Epoch: 37 [0/5000 (0%)]\tLoss: 1.563153\n","Train Epoch: 37 [2560/5000 (50%)]\tLoss: 1.571867\n","\n","Test set: Average loss: 0.0066, Accuracy: 2838/8000 (35%)\n","\n","Train Epoch: 38 [0/5000 (0%)]\tLoss: 1.561475\n","Train Epoch: 38 [2560/5000 (50%)]\tLoss: 1.634759\n","\n","Test set: Average loss: 0.0066, Accuracy: 2797/8000 (35%)\n","\n","Train Epoch: 39 [0/5000 (0%)]\tLoss: 1.678372\n","Train Epoch: 39 [2560/5000 (50%)]\tLoss: 1.644616\n","\n","Test set: Average loss: 0.0067, Accuracy: 2813/8000 (35%)\n","\n","Train Epoch: 40 [0/5000 (0%)]\tLoss: 1.675345\n","Train Epoch: 40 [2560/5000 (50%)]\tLoss: 1.592406\n","\n","Test set: Average loss: 0.0066, Accuracy: 2781/8000 (35%)\n","\n"]}],"source":["# 모델 학습\n","epochs = 40\n","dry_run = False # 1 배치만 훈련\n","\n","for epoch in range(1, epochs+1):\n","    # 학습\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 10 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.detach().cpu().item()))\n","            if dry_run:\n","                break\n","\n","    # 테스트\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        with torch.no_grad():\n","            output = model(data)\n","        test_loss += criterion(output, target).detach().cpu().item()\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    scheduler.step()\n"]},{"cell_type":"markdown","source":["VGGNet11의 경우 35%의 Accuracy로 분류했다."],"metadata":{"id":"VcLrG2ukAt__"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"EItCxBNK4vNX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689833281297,"user_tz":-540,"elapsed":257,"user":{"displayName":"손준현","userId":"05342580911122229789"}},"outputId":"4395f992-dd33-427c-8a06-3073e07950f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["convnet.0.weight\n","Parameter containing:\n","tensor([[[[-0.1144, -0.1549,  0.1741],\n","          [ 0.0975, -0.1651,  0.0737],\n","          [ 0.1242, -0.1170,  0.1480]],\n","\n","         [[-0.0786,  0.1477, -0.0866],\n","          [-0.1769, -0.0458,  0.1403],\n","          [ 0.1384,  0.1054,  0.1736]],\n","\n","         [[ 0.0095,  0.0180,  0.0244],\n","          [-0.1013, -0.0465,  0.0473],\n","          [ 0.1785,  0.1669,  0.1757]]],\n","\n","\n","        [[[-0.1443, -0.0752,  0.0551],\n","          [ 0.1028,  0.0061,  0.1706],\n","          [-0.1726,  0.0477, -0.0700]],\n","\n","         [[-0.1586,  0.0794, -0.1713],\n","          [ 0.0256,  0.1517,  0.1503],\n","          [ 0.0581,  0.0465, -0.0184]],\n","\n","         [[ 0.0417, -0.1764,  0.1138],\n","          [ 0.0143,  0.1641,  0.1871],\n","          [-0.1025, -0.0509, -0.1493]]],\n","\n","\n","        [[[ 0.0880,  0.0897,  0.1096],\n","          [-0.1456,  0.0789,  0.1025],\n","          [-0.0695,  0.0681, -0.1109]],\n","\n","         [[ 0.1342,  0.1623,  0.0980],\n","          [ 0.1525,  0.1157,  0.0131],\n","          [-0.0897,  0.1386, -0.1919]],\n","\n","         [[ 0.0600, -0.0626,  0.1071],\n","          [-0.0522,  0.1014, -0.1264],\n","          [-0.1575, -0.1483,  0.1277]]],\n","\n","\n","        ...,\n","\n","\n","        [[[-0.0895, -0.0208, -0.0791],\n","          [-0.1913,  0.1413,  0.1922],\n","          [ 0.1356,  0.0054, -0.0809]],\n","\n","         [[-0.0134,  0.0538,  0.1047],\n","          [ 0.0785, -0.0153, -0.1578],\n","          [ 0.1451, -0.1867,  0.0115]],\n","\n","         [[ 0.1499,  0.0484, -0.0441],\n","          [-0.0124, -0.0229, -0.0742],\n","          [ 0.1057, -0.1356,  0.1671]]],\n","\n","\n","        [[[-0.1713,  0.0570, -0.1435],\n","          [ 0.0601,  0.0140,  0.1426],\n","          [-0.1813, -0.1434, -0.1575]],\n","\n","         [[-0.1008, -0.1561,  0.0839],\n","          [ 0.0817, -0.1558,  0.1603],\n","          [-0.0632, -0.1890, -0.1071]],\n","\n","         [[ 0.0729, -0.0510, -0.0225],\n","          [-0.1100,  0.0931,  0.1004],\n","          [ 0.1051,  0.1809, -0.0646]]],\n","\n","\n","        [[[-0.1018,  0.0902, -0.0096],\n","          [-0.1008, -0.1371,  0.0358],\n","          [-0.1688, -0.0731, -0.1394]],\n","\n","         [[-0.0727,  0.0658, -0.0404],\n","          [ 0.1297,  0.1655,  0.1329],\n","          [-0.1873, -0.1488, -0.1459]],\n","\n","         [[ 0.1319, -0.0829, -0.1229],\n","          [-0.0286,  0.0954, -0.1359],\n","          [ 0.1277, -0.0569,  0.0437]]]], device='cuda:0', requires_grad=True)\n"]}],"source":["for name, param in model.named_parameters():\n","    print(name)\n","    print(param)\n","    break"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"jcl1PT6d_gR3"}},{"cell_type":"markdown","source":["### 2) VGGNet13 구현"],"metadata":{"id":"3gSYRRC1_heZ"}},{"cell_type":"code","source":["# VGGNet13 구현\n","class VGGNet13(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(VGGNet13, self).__init__()\n","        self.convnet = nn.Sequential(\n","            # 3x56x56\n","            nn.Conv2d(3, 64, 3, 1, 1),\n","            # 64x56x56\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 64, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 64x28x28\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","            # 128x28x28\n","            nn.ReLU(True),\n","            nn.Conv2d(128, 128, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 128x14x14\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","            # 256x14x14\n","            nn.ReLU(True),\n","            nn.Conv2d(256, 256, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 256x7x7\n","            nn.Conv2d(256, 512, 3, 1, 1),\n","            # 512x7x7\n","            nn.ReLU(True),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","\n","            # 512x3x3\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2))    # 512x1x1\n","\n","        self.fclayer = nn.Sequential(\n","            nn.Linear(512, num_classes),\n","        )\n","    def forward(self, x):\n","        x = self.convnet(x)\n","        x = torch.flatten(x, 1)\n","        output = self.fclayer(x)\n","        return output"],"metadata":{"id":"YPn6mQhJ5d0O","executionInfo":{"status":"ok","timestamp":1689834596750,"user_tz":-540,"elapsed":258,"user":{"displayName":"손준현","userId":"05342580911122229789"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"status":"ok","timestamp":1689834604740,"user_tz":-540,"elapsed":237,"user":{"displayName":"손준현","userId":"05342580911122229789"}},"id":"ag8pGUc1-lLi"},"outputs":[],"source":["model = VGGNet13(num_classes=10)"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"status":"ok","timestamp":1689834605658,"user_tz":-540,"elapsed":2,"user":{"displayName":"손준현","userId":"05342580911122229789"}},"id":"7gIWS_kv-lLo"},"outputs":[],"source":["# 학습을 위한 설정\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters(),lr=1e-5)\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec7e7f6d-57ab-454b-d819-a9fb657d96d9","executionInfo":{"status":"ok","timestamp":1689835222978,"user_tz":-540,"elapsed":616337,"user":{"displayName":"손준현","userId":"05342580911122229789"}},"id":"0oXq7TzL-lLo"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.301809\n","Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.303134\n","\n","Test set: Average loss: 0.0092, Accuracy: 800/8000 (10%)\n","\n","Train Epoch: 2 [0/5000 (0%)]\tLoss: 2.301107\n","Train Epoch: 2 [2560/5000 (50%)]\tLoss: 2.300568\n","\n","Test set: Average loss: 0.0092, Accuracy: 800/8000 (10%)\n","\n","Train Epoch: 3 [0/5000 (0%)]\tLoss: 2.303256\n","Train Epoch: 3 [2560/5000 (50%)]\tLoss: 2.302809\n","\n","Test set: Average loss: 0.0092, Accuracy: 1442/8000 (18%)\n","\n","Train Epoch: 4 [0/5000 (0%)]\tLoss: 2.303887\n","Train Epoch: 4 [2560/5000 (50%)]\tLoss: 2.300164\n","\n","Test set: Average loss: 0.0092, Accuracy: 1440/8000 (18%)\n","\n","Train Epoch: 5 [0/5000 (0%)]\tLoss: 2.295112\n","Train Epoch: 5 [2560/5000 (50%)]\tLoss: 2.287615\n","\n","Test set: Average loss: 0.0090, Accuracy: 1403/8000 (18%)\n","\n","Train Epoch: 6 [0/5000 (0%)]\tLoss: 2.259987\n","Train Epoch: 6 [2560/5000 (50%)]\tLoss: 2.181263\n","\n","Test set: Average loss: 0.0085, Accuracy: 1479/8000 (18%)\n","\n","Train Epoch: 7 [0/5000 (0%)]\tLoss: 2.105456\n","Train Epoch: 7 [2560/5000 (50%)]\tLoss: 2.049760\n","\n","Test set: Average loss: 0.0084, Accuracy: 1651/8000 (21%)\n","\n","Train Epoch: 8 [0/5000 (0%)]\tLoss: 2.166657\n","Train Epoch: 8 [2560/5000 (50%)]\tLoss: 2.087334\n","\n","Test set: Average loss: 0.0082, Accuracy: 1817/8000 (23%)\n","\n","Train Epoch: 9 [0/5000 (0%)]\tLoss: 2.122536\n","Train Epoch: 9 [2560/5000 (50%)]\tLoss: 2.039647\n","\n","Test set: Average loss: 0.0081, Accuracy: 2019/8000 (25%)\n","\n","Train Epoch: 10 [0/5000 (0%)]\tLoss: 1.993497\n","Train Epoch: 10 [2560/5000 (50%)]\tLoss: 2.055595\n","\n","Test set: Average loss: 0.0080, Accuracy: 1977/8000 (25%)\n","\n","Train Epoch: 11 [0/5000 (0%)]\tLoss: 2.086964\n","Train Epoch: 11 [2560/5000 (50%)]\tLoss: 1.970518\n","\n","Test set: Average loss: 0.0079, Accuracy: 2126/8000 (27%)\n","\n","Train Epoch: 12 [0/5000 (0%)]\tLoss: 1.960616\n","Train Epoch: 12 [2560/5000 (50%)]\tLoss: 1.986303\n","\n","Test set: Average loss: 0.0078, Accuracy: 2179/8000 (27%)\n","\n","Train Epoch: 13 [0/5000 (0%)]\tLoss: 1.974732\n","Train Epoch: 13 [2560/5000 (50%)]\tLoss: 1.902065\n","\n","Test set: Average loss: 0.0077, Accuracy: 2105/8000 (26%)\n","\n","Train Epoch: 14 [0/5000 (0%)]\tLoss: 1.902646\n","Train Epoch: 14 [2560/5000 (50%)]\tLoss: 1.859537\n","\n","Test set: Average loss: 0.0075, Accuracy: 2341/8000 (29%)\n","\n","Train Epoch: 15 [0/5000 (0%)]\tLoss: 1.830390\n","Train Epoch: 15 [2560/5000 (50%)]\tLoss: 1.906153\n","\n","Test set: Average loss: 0.0074, Accuracy: 2465/8000 (31%)\n","\n","Train Epoch: 16 [0/5000 (0%)]\tLoss: 1.891315\n","Train Epoch: 16 [2560/5000 (50%)]\tLoss: 1.857311\n","\n","Test set: Average loss: 0.0073, Accuracy: 2376/8000 (30%)\n","\n","Train Epoch: 17 [0/5000 (0%)]\tLoss: 1.883761\n","Train Epoch: 17 [2560/5000 (50%)]\tLoss: 1.825856\n","\n","Test set: Average loss: 0.0073, Accuracy: 2442/8000 (31%)\n","\n","Train Epoch: 18 [0/5000 (0%)]\tLoss: 1.739762\n","Train Epoch: 18 [2560/5000 (50%)]\tLoss: 1.720631\n","\n","Test set: Average loss: 0.0072, Accuracy: 2442/8000 (31%)\n","\n","Train Epoch: 19 [0/5000 (0%)]\tLoss: 1.828667\n","Train Epoch: 19 [2560/5000 (50%)]\tLoss: 1.720616\n","\n","Test set: Average loss: 0.0072, Accuracy: 2378/8000 (30%)\n","\n","Train Epoch: 20 [0/5000 (0%)]\tLoss: 1.790363\n","Train Epoch: 20 [2560/5000 (50%)]\tLoss: 1.731643\n","\n","Test set: Average loss: 0.0071, Accuracy: 2520/8000 (32%)\n","\n","Train Epoch: 21 [0/5000 (0%)]\tLoss: 1.746407\n","Train Epoch: 21 [2560/5000 (50%)]\tLoss: 1.766810\n","\n","Test set: Average loss: 0.0070, Accuracy: 2539/8000 (32%)\n","\n","Train Epoch: 22 [0/5000 (0%)]\tLoss: 1.811006\n","Train Epoch: 22 [2560/5000 (50%)]\tLoss: 1.745044\n","\n","Test set: Average loss: 0.0071, Accuracy: 2490/8000 (31%)\n","\n","Train Epoch: 23 [0/5000 (0%)]\tLoss: 1.789509\n","Train Epoch: 23 [2560/5000 (50%)]\tLoss: 1.611773\n","\n","Test set: Average loss: 0.0069, Accuracy: 2635/8000 (33%)\n","\n","Train Epoch: 24 [0/5000 (0%)]\tLoss: 1.725195\n","Train Epoch: 24 [2560/5000 (50%)]\tLoss: 1.601410\n","\n","Test set: Average loss: 0.0069, Accuracy: 2648/8000 (33%)\n","\n","Train Epoch: 25 [0/5000 (0%)]\tLoss: 1.618110\n","Train Epoch: 25 [2560/5000 (50%)]\tLoss: 1.720581\n","\n","Test set: Average loss: 0.0069, Accuracy: 2668/8000 (33%)\n","\n","Train Epoch: 26 [0/5000 (0%)]\tLoss: 1.660802\n","Train Epoch: 26 [2560/5000 (50%)]\tLoss: 1.687745\n","\n","Test set: Average loss: 0.0068, Accuracy: 2673/8000 (33%)\n","\n","Train Epoch: 27 [0/5000 (0%)]\tLoss: 1.682669\n","Train Epoch: 27 [2560/5000 (50%)]\tLoss: 1.662834\n","\n","Test set: Average loss: 0.0069, Accuracy: 2665/8000 (33%)\n","\n","Train Epoch: 28 [0/5000 (0%)]\tLoss: 1.642848\n","Train Epoch: 28 [2560/5000 (50%)]\tLoss: 1.682462\n","\n","Test set: Average loss: 0.0068, Accuracy: 2695/8000 (34%)\n","\n","Train Epoch: 29 [0/5000 (0%)]\tLoss: 1.667570\n","Train Epoch: 29 [2560/5000 (50%)]\tLoss: 1.675910\n","\n","Test set: Average loss: 0.0068, Accuracy: 2655/8000 (33%)\n","\n","Train Epoch: 30 [0/5000 (0%)]\tLoss: 1.718689\n","Train Epoch: 30 [2560/5000 (50%)]\tLoss: 1.635548\n","\n","Test set: Average loss: 0.0068, Accuracy: 2675/8000 (33%)\n","\n","Train Epoch: 31 [0/5000 (0%)]\tLoss: 1.591240\n","Train Epoch: 31 [2560/5000 (50%)]\tLoss: 1.687472\n","\n","Test set: Average loss: 0.0067, Accuracy: 2750/8000 (34%)\n","\n","Train Epoch: 32 [0/5000 (0%)]\tLoss: 1.671217\n","Train Epoch: 32 [2560/5000 (50%)]\tLoss: 1.709990\n","\n","Test set: Average loss: 0.0067, Accuracy: 2798/8000 (35%)\n","\n","Train Epoch: 33 [0/5000 (0%)]\tLoss: 1.644550\n","Train Epoch: 33 [2560/5000 (50%)]\tLoss: 1.608745\n","\n","Test set: Average loss: 0.0067, Accuracy: 2734/8000 (34%)\n","\n","Train Epoch: 34 [0/5000 (0%)]\tLoss: 1.669919\n","Train Epoch: 34 [2560/5000 (50%)]\tLoss: 1.659692\n","\n","Test set: Average loss: 0.0067, Accuracy: 2759/8000 (34%)\n","\n","Train Epoch: 35 [0/5000 (0%)]\tLoss: 1.777619\n","Train Epoch: 35 [2560/5000 (50%)]\tLoss: 1.700453\n","\n","Test set: Average loss: 0.0067, Accuracy: 2752/8000 (34%)\n","\n","Train Epoch: 36 [0/5000 (0%)]\tLoss: 1.607861\n","Train Epoch: 36 [2560/5000 (50%)]\tLoss: 1.682232\n","\n","Test set: Average loss: 0.0067, Accuracy: 2789/8000 (35%)\n","\n","Train Epoch: 37 [0/5000 (0%)]\tLoss: 1.600194\n","Train Epoch: 37 [2560/5000 (50%)]\tLoss: 1.642006\n","\n","Test set: Average loss: 0.0067, Accuracy: 2751/8000 (34%)\n","\n","Train Epoch: 38 [0/5000 (0%)]\tLoss: 1.687155\n","Train Epoch: 38 [2560/5000 (50%)]\tLoss: 1.667297\n","\n","Test set: Average loss: 0.0067, Accuracy: 2786/8000 (35%)\n","\n","Train Epoch: 39 [0/5000 (0%)]\tLoss: 1.594750\n","Train Epoch: 39 [2560/5000 (50%)]\tLoss: 1.707040\n","\n","Test set: Average loss: 0.0067, Accuracy: 2758/8000 (34%)\n","\n","Train Epoch: 40 [0/5000 (0%)]\tLoss: 1.583397\n","Train Epoch: 40 [2560/5000 (50%)]\tLoss: 1.589767\n","\n","Test set: Average loss: 0.0067, Accuracy: 2762/8000 (35%)\n","\n"]}],"source":["# 모델 학습\n","epochs = 40\n","dry_run = False # 1 배치만 훈련\n","\n","for epoch in range(1, epochs+1):\n","    # 학습\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 10 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.detach().cpu().item()))\n","            if dry_run:\n","                break\n","\n","    # 테스트\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        with torch.no_grad():\n","            output = model(data)\n","        test_loss += criterion(output, target).detach().cpu().item()\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    scheduler.step()\n"]},{"cell_type":"markdown","source":["VGGNet13의 경우 35%의 Accuracy로 분류했다."],"metadata":{"id":"EhxOCmDaCBuX"}},{"cell_type":"code","source":[],"metadata":{"id":"6Mf4YagV-4Yx"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}